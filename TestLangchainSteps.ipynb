{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# In TestAPi.ipynb, add:\n",
    "from send_request import load_codebase\n",
    "\n",
    "# Load a directory of Python files\n",
    "load_codebase(\"C:/Users/eswar/Downloads/chat-with-code-main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from send_request import ask_codebase\n",
    "\n",
    "# Ask about the loaded codebase\n",
    "ask_codebase(\"What does this code do?\", model=\"deepseek-r1:1.5b\", provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from send_request import ask_codebase\n",
    "\n",
    "# Ask about the loaded codebase\n",
    "ask_codebase(\"I would like to know more about chatbot.py and its funtions what each funtion do\", model=\"deepseek-r1:1.5b\", provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from send_request import ask_codebase\n",
    "\n",
    "# Ask about the loaded codebase\n",
    "ask_codebase(\"What does this code do?\", model=\"deepseek-r1:1.5b\", provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from send_request import ask_codebase\n",
    "\n",
    "# Ask about the loaded codebase\n",
    "ask_codebase(\"I would like to know more about chatbot.py and its funtions what each funtion do\", model=\"deepseek-r1:1.5b\", provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Import debug utilities\n",
    "from debug.notebook_utils import DebugUtils\n",
    "from debug.debug_retrieval import debug_retrieval\n",
    "from debug.visualization import plot_similarity_distribution, plot_retrieval_comparison, create_heatmap\n",
    "\n",
    "# Initialize debug utils\n",
    "debug_utils = DebugUtils()\n",
    "\n",
    "# 1. Visualize retrieval for a specific question\n",
    "question = \"What does the generate_response function do?\"\n",
    "debug_utils.visualize_retrieval(question, k=5)\n",
    "\n",
    "# 2. Plot similarity scores for the retrieved chunks\n",
    "debug_utils.plot_similarity_scores(question, k=5)\n",
    "\n",
    "# 3. Try different retrieval parameters and compare\n",
    "results = [\n",
    "    {\"k\": 3, \"search_type\": \"similarity\", \"count\": 3},\n",
    "    {\"k\": 5, \"search_type\": \"similarity\", \"count\": 5},\n",
    "    {\"k\": 7, \"search_type\": \"similarity\", \"count\": 7}\n",
    "]\n",
    "plot_retrieval_comparison(question, results, metric=\"count\", title=\"Comparison of Retrieval Parameters\")\n",
    "\n",
    "# 4. For more detailed CLI-style output (will display in notebook output cell)\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "with console.capture() as capture:\n",
    "    debug_retrieval(question, k=5)\n",
    "output = capture.get()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Advanced debugging: Compare different questions\n",
    "import os  # Add missing import\n",
    "import numpy as np\n",
    "\n",
    "questions = [\n",
    "    \"What does the generate_response function do?\",\n",
    "    \"How does the code handle user input?\",\n",
    "    \"What is the main purpose of chatbot.py?\"\n",
    "]\n",
    "\n",
    "# Create a heatmap to visualize document relevance across questions\n",
    "\n",
    "# Get documents for each question\n",
    "all_docs = []\n",
    "all_sources = set()\n",
    "for q in questions:\n",
    "    retriever = debug_utils.vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "    docs = retriever.get_relevant_documents(q)\n",
    "    all_docs.append(docs)\n",
    "    for doc in docs:\n",
    "        all_sources.add(doc.metadata.get(\"source\", \"Unknown\"))\n",
    "\n",
    "# Create a matrix of document relevance\n",
    "sources_list = list(all_sources)\n",
    "matrix = np.zeros((len(questions), len(sources_list)))\n",
    "\n",
    "for i, docs in enumerate(all_docs):\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "        j = sources_list.index(source)\n",
    "        matrix[i, j] = 1  # Mark as relevant\n",
    "\n",
    "# Create the heatmap\n",
    "create_heatmap(\n",
    "    similarity_matrix=matrix,\n",
    "    x_labels=[os.path.basename(s) for s in sources_list],\n",
    "    y_labels=[f\"Q{i+1}: {q[:20]}...\" for i, q in enumerate(questions)],\n",
    "    title=\"Document Relevance Across Different Questions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
